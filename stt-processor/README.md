# STT Processor (Module 2)

**Speech-to-Text processor for AetherOS using Whisper.cpp**

Production-grade streaming STT service with <2s latency for real-time transcription.

## üéØ Overview

The STT Processor converts audio from the Wake-word Detector into text transcriptions using OpenAI's Whisper model via whisper.cpp bindings. It handles audio preprocessing, streaming chunk processing, and provides both batch and real-time transcription APIs.

### Key Features

- **Real-time Streaming**: 500ms chunks with 50ms overlap
- **High Performance**: <2s latency for 10s audio
- **Audio Preprocessing**: Automatic resampling, normalization, format conversion
- **Confidence Scoring**: Per-segment transcription confidence estimation
- **Async Processing**: Non-blocking I/O with Tokio runtime
- **Production Ready**: Graceful shutdown, error handling, backpressure management

### Architecture Position

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Agent Core  ‚îÇ
‚îÇ    (Module)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚Üì gRPC
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   STT Processor (M2)  ‚îÇ ‚Üê YOU ARE HERE
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Streaming STT   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ (500ms chunks)  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ           ‚îÇ           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Audio Preproc   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ (Resample+Norm) ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ           ‚îÇ           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Whisper.cpp     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ (Transcription) ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üë
        ‚îÇ Audio buffer
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Wakeword     ‚îÇ
‚îÇ Detector (M1) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ Quick Start

### Prerequisites

- **Rust**: 1.75 or later
- **Whisper Model**: Download `ggml-base.en.bin` (~140MB)
- **Audio Input**: 16kHz mono PCM format

### Installation

```bash
# Clone and navigate to stt-processor
cd stt-processor

# Download Whisper model
cd models
wget https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.en.bin
cd ..

# Build release binary
cargo build --release

# Run tests
cargo test

# Run benchmarks
cargo bench
```

### Basic Usage

#### As a Library

```rust
use stt_processor::{WhisperProcessor, WhisperConfig, AudioPreprocessor, AudioFormat};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Initialize Whisper
    let config = WhisperConfig {
        model_path: "models/ggml-base.en.bin".into(),
        language: "en".into(),
        num_threads: 4,
        ..Default::default()
    };
    let whisper = WhisperProcessor::new(config)?;

    // Setup audio preprocessor
    let input_format = AudioFormat::new(44100, 1, 16); // 44.1kHz input
    let preprocessor = AudioPreprocessor::new(input_format)?;

    // Process audio
    let audio_samples: Vec<f32> = vec![/* your audio data */];
    let processed = preprocessor.process(&audio_samples)?;

    // Transcribe
    let result = whisper.transcribe(&processed)?;
    println!("Transcription: {}", result.text);
    println!("Confidence: {:.2}", result.confidence);
    println!("Latency: {}ms", result.processing_time_ms);

    Ok(())
}
```

#### Streaming Mode

```rust
use stt_processor::{StreamingSTT, StreamingConfig, StreamingEvent};
use std::sync::Arc;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let whisper = Arc::new(WhisperProcessor::new(config)?);
    let input_format = AudioFormat::whisper_format();
    let streaming_config = StreamingConfig::default();

    let streaming_stt = StreamingSTT::new(whisper, input_format, streaming_config)?;
    streaming_stt.start().await?;

    // Process audio chunks
    loop {
        let chunk: Vec<f32> = get_audio_chunk().await; // Your audio source

        if let Some(event) = streaming_stt.process_chunk(&chunk).await? {
            match event {
                StreamingEvent::Partial { text, confidence, .. } => {
                    println!("Partial: {} ({:.0}%)", text, confidence * 100.0);
                }
                StreamingEvent::Final { text, confidence, .. } => {
                    println!("Final: {} ({:.0}%)", text, confidence * 100.0);
                }
                StreamingEvent::Error { error } => {
                    eprintln!("Error: {}", error);
                }
            }
        }
    }
}
```

#### As a Service

```bash
# Set environment variables
export WHISPER_MODEL_PATH="models/ggml-base.en.bin"
export WHISPER_NUM_THREADS=4
export WHISPER_LANGUAGE="en"

# Run the service
./target/release/stt-processor

# Service will listen for gRPC requests from Agent Core
```

## üì¶ Components

### Audio Preprocessor (`audio_preprocessor.rs`)

Prepares audio for Whisper transcription:

- **Resampling**: Converts any sample rate to 16kHz using high-quality sinc interpolation
- **Channel Conversion**: Stereo ‚Üí mono downmixing
- **Normalization**: Peak normalization with 5% headroom
- **Format Conversion**: i16 PCM ‚Üî f32 normalized samples

**Example:**

```rust
let format = AudioFormat::new(48000, 2, 16); // 48kHz stereo
let preprocessor = AudioPreprocessor::new(format)?;

let stereo_audio: Vec<f32> = load_audio_file("input.wav");
let whisper_ready = preprocessor.process(&stereo_audio)?;
// Output: 16kHz mono f32 samples, ready for Whisper
```

### Whisper Wrapper (`whisper_wrapper.rs`)

Safe Rust bindings to whisper.cpp:

- **Model Management**: Automatic model loading and validation
- **Transcription API**: Synchronous transcription with timeout support
- **Confidence Estimation**: Heuristic confidence scoring based on repeated tokens
- **Error Handling**: Proper cleanup on failures

**Configuration:**

```rust
pub struct WhisperConfig {
    pub model_path: PathBuf,           // Path to ggml model file
    pub language: String,              // "en", "es", "fr", etc.
    pub translate: bool,               // Translate to English
    pub num_threads: usize,            // CPU threads (0 = auto)
    pub print_progress: bool,          // Debug logging
}
```

### Streaming STT (`streaming.rs`)

Real-time chunk processing:

- **Chunking**: 500ms chunks with 50ms overlap for context continuity
- **Async Processing**: Non-blocking with tokio channels
- **Backpressure**: Queue size limits to prevent memory bloat
- **State Management**: Partial result accumulation across chunks

**Configuration:**

```rust
pub struct StreamingConfig {
    pub chunk_duration_ms: u32,        // Default: 500ms
    pub overlap_ms: u32,               // Default: 50ms
    pub enable_partial_results: bool,  // Stream intermediate results
    pub max_queue_size: usize,         // Backpressure threshold
}
```

## ‚öôÔ∏è Configuration

### Environment Variables

```bash
# Required
WHISPER_MODEL_PATH=models/ggml-base.en.bin

# Optional (defaults shown)
WHISPER_NUM_THREADS=0              # 0 = auto-detect
WHISPER_LANGUAGE=en                # ISO 639-1 code
WHISPER_TRANSLATE=false            # Translate to English
WHISPER_PRINT_PROGRESS=false       # Debug logging
```

### Audio Format Support

| Parameter   | Supported Values     | Recommended    |
| ----------- | -------------------- | -------------- |
| Sample Rate | 8kHz - 48kHz         | 16kHz (native) |
| Channels    | 1 (mono), 2 (stereo) | 1 (mono)       |
| Bit Depth   | 16-bit, 32-bit float | 32-bit float   |
| Encoding    | PCM, IEEE float      | IEEE float     |

**Note:** Whisper internally uses 16kHz mono. Other formats are automatically converted.

## üß™ Testing

### Unit Tests

```bash
# Run all tests
cargo test

# Run with output
cargo test -- --nocapture

# Test specific module
cargo test audio_preprocessor
cargo test whisper_wrapper
cargo test streaming
```

### Integration Tests

```bash
# Full end-to-end tests (requires model file)
cargo test --test integration_test

# Note: Some tests are disabled by default (require model download)
# Uncomment tests in tests/integration_test.rs after downloading model
```

### Benchmarks

```bash
# Run all benchmarks
cargo bench

# Benchmark specific component
cargo bench audio_preprocessing
cargo bench transcription

# Generate flamegraph
cargo bench --bench transcription_bench -- --profile-time=5
```

**Expected Performance:**

- Audio preprocessing: <10ms for 1s audio
- Transcription: <2s for 10s audio (base.en model on modern CPU)
- Streaming latency: ~500ms end-to-end

## üîç Troubleshooting

### Model Loading Fails

**Error:** `Failed to load model: No such file or directory`

**Solution:**

```bash
cd models
wget https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.en.bin
chmod 644 ggml-base.en.bin
```

### High Latency

**Symptoms:** Transcription takes >2s for 10s audio

**Diagnosis:**

```bash
# Check CPU usage
cargo bench transcription

# Try different thread counts
WHISPER_NUM_THREADS=8 ./target/release/stt-processor
```

**Solutions:**

- Use smaller model (tiny.en or base.en)
- Increase `num_threads` to match CPU cores
- Enable GPU acceleration (Metal for macOS, CUDA for Linux)

### Audio Quality Issues

**Symptoms:** Low confidence scores, garbled transcriptions

**Diagnosis:**

```rust
// Check preprocessing output
let processed = preprocessor.process(&audio)?;
println!("RMS: {:.3}", rms(&processed));
println!("Peak: {:.3}", peak(&processed));
println!("Length: {} samples", processed.len());
```

**Solutions:**

- Verify input audio is not corrupted
- Check sample rate matches AudioFormat
- Ensure audio is speech (not music/silence)
- Normalize audio levels before processing

### Memory Issues

**Symptoms:** OOM errors, high memory usage

**Solutions:**

```rust
// Reduce streaming queue size
let config = StreamingConfig {
    max_queue_size: 10, // Reduce from default 100
    ..Default::default()
};

// Process shorter chunks
let config = StreamingConfig {
    chunk_duration_ms: 250, // Reduce from 500ms
    ..Default::default()
};
```

## üìä Performance Characteristics

### Latency Targets

| Audio Duration | Target Latency | Typical |
| -------------- | -------------- | ------- |
| 1s             | <200ms         | ~150ms  |
| 5s             | <1s            | ~800ms  |
| 10s            | <2s            | ~1.5s   |
| 30s            | <5s            | ~4s     |

### Resource Usage

| Component           | CPU             | Memory | GPU      |
| ------------------- | --------------- | ------ | -------- |
| Audio Preprocessing | ~5%             | ~10MB  | N/A      |
| Whisper base.en     | ~200% (2 cores) | ~500MB | Optional |
| Streaming           | ~10%            | ~50MB  | N/A      |

**Total:** ~2-3 cores, ~600MB RAM for typical workload

## üîó Dependencies

### Critical Path Position

```
M1 (Wake-word) ‚Üí M2 (STT) ‚Üí M10 (Memory) ‚Üí M4 (Intent) ‚Üí M5 (Orchestration)
                   ‚Üë YOU ARE HERE
```

**Upstream:**

- Module 1 (Wake-word Detector): Provides 3-second audio context on wake-word detection

**Downstream:**

- Module 10 (Memory Service): Stores transcriptions for context
- Module 4 (Intent Classifier): Analyzes transcribed text for user intent

### External Dependencies

- **whisper-rs**: Rust bindings to whisper.cpp
- **rubato**: High-quality audio resampling
- **tokio**: Async runtime for streaming
- **hound**: WAV file I/O for testing

## üõ†Ô∏è Development

### Project Structure

```
stt-processor/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ audio_preprocessor.rs    # Resampling, normalization (348 lines)
‚îÇ   ‚îú‚îÄ‚îÄ whisper_wrapper.rs       # Whisper.cpp bindings (390 lines)
‚îÇ   ‚îú‚îÄ‚îÄ streaming.rs             # Streaming STT (260 lines)
‚îÇ   ‚îú‚îÄ‚îÄ lib.rs                   # Public API exports
‚îÇ   ‚îî‚îÄ‚îÄ main.rs                  # Service binary
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ integration_test.rs      # End-to-end tests
‚îú‚îÄ‚îÄ benches/
‚îÇ   ‚îî‚îÄ‚îÄ transcription_bench.rs   # Performance benchmarks
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ README.md                # Model download guide
‚îî‚îÄ‚îÄ Cargo.toml
```

### Building from Source

```bash
# Development build
cargo build

# Release build (optimized)
cargo build --release

# Check for errors
cargo check

# Format code
cargo fmt

# Lint
cargo clippy
```

### Adding New Models

1. Download model from [Hugging Face](https://huggingface.co/ggerganov/whisper.cpp):

```bash
cd models

# Tiny (75MB, fastest)
wget https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.en.bin

# Base (142MB, balanced)
wget https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.en.bin

# Small (466MB, more accurate)
wget https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-small.en.bin
```

2. Update configuration:

```bash
export WHISPER_MODEL_PATH=models/ggml-small.en.bin
```

3. Benchmark performance:

```bash
cargo bench transcription
```

## üìù API Reference

### Core Types

```rust
// Audio format descriptor
pub struct AudioFormat {
    pub sample_rate: u32,
    pub channels: u8,
    pub bit_depth: u8,
}

// Transcription result
pub struct TranscriptionResult {
    pub text: String,
    pub confidence: f32,
    pub processing_time_ms: u64,
}

// Streaming events
pub enum StreamingEvent {
    Partial { text: String, confidence: f32, chunk_index: usize },
    Final { text: String, confidence: f32, total_chunks: usize },
    Error { error: String },
}
```

### Main Interfaces

```rust
// Audio preprocessing
impl AudioPreprocessor {
    pub fn new(input_format: AudioFormat) -> Result<Self>;
    pub fn process(&self, audio: &[AudioSample]) -> Result<Vec<AudioSample>>;
}

// Whisper transcription
impl WhisperProcessor {
    pub fn new(config: WhisperConfig) -> Result<Self>;
    pub fn transcribe(&self, audio: &[AudioSample]) -> Result<TranscriptionResult>;
}

// Streaming STT
impl StreamingSTT {
    pub fn new(whisper: Arc<WhisperProcessor>, input_format: AudioFormat, config: StreamingConfig) -> Result<Self>;
    pub async fn start(&self) -> Result<()>;
    pub async fn process_chunk(&self, audio: &[AudioSample]) -> Result<Option<StreamingEvent>>;
    pub async fn stop(&self) -> Result<()>;
}
```

## üìÑ License

Part of the AetherOS project.

## ü§ù Contributing

This module is part of the critical path for AetherOS. Changes must maintain:

- **Latency:** <2s for 10s audio
- **Accuracy:** >95% word error rate on LibriSpeech
- **Reliability:** No crashes on malformed audio input
- **API Stability:** Backward compatibility for downstream modules

## üìß Support

For issues specific to this module, see the AetherOS project documentation.

## üîÑ Next Steps

Once Module 2 is complete and tested:

1. **Module 10** (Memory Service): Store transcriptions for context
2. **Module 4** (Intent Classifier): Parse user commands from transcribed text
3. **Integration Testing**: End-to-end with M1 ‚Üí M2 ‚Üí M10 ‚Üí M4 pipeline
